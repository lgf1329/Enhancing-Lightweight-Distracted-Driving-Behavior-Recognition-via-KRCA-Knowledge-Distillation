# Enhancing-Lightweight-Distracted-Driving-Behavior-Recognition-via-KRCA-Knowledge-Distillation
ðŸš€ â€‹â€‹KRCA-Distilled Lightweight Model for Real-time Distracted Driving Recognitionâ€‹â€‹

â€‹â€‹Revolutionizing edge deployment with multi-knowledge distillation and light robustness optimizationâ€‹â€‹

This repository presents a groundbreaking lightweight framework for driver distraction recognition, achieving â€‹â€‹99.83% accuracyâ€‹â€‹ with only â€‹â€‹187.43K parametersâ€‹â€‹. Our novel KRCA (Knowledge Relation Comparison with Attention) distillation method synergistically combines four complementary knowledge types for the first time in driving behavior recognition, overcoming traditional distillation's limitations in handling light variations and behavioral similarities.

![FIG1](https://github.com/user-attachments/assets/7423dfef-c3dc-4f2f-b7e7-65a6da380ef4)

